
model.embed_tokens.weight: torch.Size([151936, 1024])

model.layers.0.input_layernorm.weight: torch.Size([1024])
model.layers.0.self_attn.q_proj.weight: torch.Size([2048, 1024])
model.layers.0.self_attn.k_proj.weight: torch.Size([1024, 1024])
model.layers.0.self_attn.v_proj.weight: torch.Size([1024, 1024])
model.layers.0.self_attn.o_proj.weight: torch.Size([1024, 2048])
model.layers.0.self_attn.q_norm.weight: torch.Size([128])
model.layers.0.self_attn.k_norm.weight: torch.Size([128])

model.layers.0.post_attention_layernorm.weight: torch.Size([1024])
model.layers.0.mlp.up_proj.weight: torch.Size([3072, 1024])
model.layers.0.mlp.gate_proj.weight: torch.Size([3072, 1024])
model.layers.0.mlp.down_proj.weight: torch.Size([1024, 3072])

model.norm.weight: torch.Size([1024])
lm_head.weight: torch.Size([151936, 1024])
